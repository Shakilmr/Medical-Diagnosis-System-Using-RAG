{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"/Users/shakil/Downloads/RAG-Chatbot/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#extracted_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "# Assume extracted_data is defined somewhere\n",
    "text_chunks = text_split(extracted_data)  # Call the function to get text chunks\n",
    "\n",
    "print(\"Length of Text Chunks\", len(text_chunks))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "# Call the function and assign the result to a global variable\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "\n",
    "# Now you can use the embeddings object\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length:\", len(query_result))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pinecode Index using Code\n",
    "from pinecone import Pinecone, ServerlessSpec  # Import the required classes  \n",
    "# Initialize Pinecone with an instance \n",
    "pc = Pinecone(api_key=\"pcsk_4NC22q_T6VQeA3w4cLszg6TQcFYpjQzUVWdqkHSN3oJbHJfw5QVkFdTLKg49oUYPQAfcTj\")  \n",
    "# Replace with your actual API key  \n",
    "# Define index name \n",
    "index_name = \"medibot\"  \n",
    "# Create the index if it doesn't exist if index_name not in pc.list_indexes():    \n",
    "pc.create_index(\n",
    "\tname=index_name,         \n",
    "\tdimension=384,         \n",
    "\tmetric=\"cosine\",         \n",
    "\tspec=ServerlessSpec\n",
    "\t(             \n",
    "\t\tcloud=\"aws\",             \n",
    "\t\tregion=\"us-east-1\"         \n",
    "\t)     \n",
    ")\n",
    "#Using the same code we created the medicalbot index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Set your Pinecone API key directly as a string\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_4NC22q_T6VQeA3w4cLszg6TQcFYpjQzUVWdqkHSN3oJbHJfw5QVkFdTLKg49oUYPQAfcTj\"\n",
    "\n",
    "# Verify that the environment variable is set correctly\n",
    "print(os.environ[\"PINECONE_API_KEY\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # Updated import\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "# Step 1: Split text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)  \n",
    "print(\"Length of Text Chunks:\", len(text_chunks))\n",
    "\n",
    "# Step 2: Download Hugging Face embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of Embedding Vector:\", len(query_result))\n",
    "\n",
    "# Step 3: Upload vector embeddings to Pinecone\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"medibot\"\n",
    ")\n",
    "\n",
    "print(\"Vector embeddings uploaded to Pinecone successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Set your Pinecone API key and environment\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_4NC22q_T6VQeA3w4cLszg6TQcFYpjQzUVWdqkHSN3oJbHJfw5QVkFdTLKg49oUYPQAfcTj\"\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = \"us-east-1\"  # Optional\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Specify your existing index name\n",
    "index_name = \"testbot\"\n",
    "\n",
    "# Load the existing Pinecone index\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"Existing Pinecone index loaded successfully.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = docsearch.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":3})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = retriever.invoke(\"What is diabetes?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "\n",
    "# Set your Pinecone API key and environment\n",
    "os.environ[\"PINECONE_API_KEY\"] = \"pcsk_3FxEjX_PU14iod1t5qbzFUTBqnraZwCrLKYnT6Gbsf2z2bhKpmQGr4MCBHAUJJwTCbGh96\"\n",
    "os.environ[\"PINECONE_ENVIRONMENT\"] = \"us-east-1\"  # Optional\n",
    "\n",
    "# Initialize the embeddings model\n",
    "embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "\n",
    "# Specify your existing index name\n",
    "index_name = \"medicalbot\"\n",
    "\n",
    "# Load the existing Pinecone index\n",
    "vector_store = PineconeVectorStore.from_existing_index(\n",
    "    index_name=index_name,\n",
    "    embedding=embeddings\n",
    ")\n",
    "\n",
    "print(\"Existing Pinecone index loaded successfully.\")\n",
    "\n",
    "from langchain.document_loaders import DirectoryLoader, PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "#Extract data from the PDF\n",
    "def load_pdf(data):\n",
    "    loader = DirectoryLoader(data,\n",
    "                    glob=\"*.pdf\",\n",
    "                    loader_cls=PyPDFLoader)\n",
    "    \n",
    "    documents = loader.load()\n",
    "\n",
    "    return documents\n",
    "\n",
    "extracted_data = load_pdf(\"/Users/mubtasimfuad/Downloads/RAG-CHATBOT/data\") \n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # Updated import\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "# Step 1: Split text into chunks\n",
    "def text_split(extracted_data):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=20)\n",
    "    text_chunks = text_splitter.split_documents(extracted_data)\n",
    "    return text_chunks\n",
    "\n",
    "text_chunks = text_split(extracted_data)  \n",
    "print(\"Length of Text Chunks:\", len(text_chunks))\n",
    "\n",
    "# Step 2: Download Hugging Face embeddings\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of Embedding Vector:\", len(query_result))\n",
    "\n",
    "# Step 3: Upload vector embeddings to Pinecone\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents=text_chunks,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"medicalbot\"\n",
    ")\n",
    "\n",
    "print(\"Medical book Vector embeddings uploaded to Pinecone successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Pinecode Index using Code\n",
    "from pinecone import Pinecone, ServerlessSpec  # Import the required classes  \n",
    "# Initialize Pinecone with an instance \n",
    "pc = Pinecone(api_key=\"pcsk_4NC22q_T6VQeA3w4cLszg6TQcFYpjQzUVWdqkHSN3oJbHJfw5QVkFdTLKg49oUYPQAfcTj\")  \n",
    "# Replace with your actual API key  \n",
    "# Define index name \n",
    "index_name = \"medicalbot\"  \n",
    "# Create the index if it doesn't exist if index_name not in pc.list_indexes():    \n",
    "pc.create_index(\n",
    "\tname=index_name,         \n",
    "\tdimension=384,         \n",
    "\tmetric=\"cosine\",         \n",
    "\tspec=ServerlessSpec\n",
    "\t(             \n",
    "\t\tcloud=\"aws\",             \n",
    "\t\tregion=\"us-east-1\"         \n",
    "\t)     \n",
    ")\n",
    "#Using the same code we created the medicalbot index  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from langchain.docstore.document import Document\n",
    "from langchain_huggingface import HuggingFaceEmbeddings  # Updated import\n",
    "from langchain_community.vectorstores import Pinecone\n",
    "\n",
    "# --- Step 1: Split extracted PDF data into numbered rows ---\n",
    "\n",
    "def split_into_numbered_rows(documents):\n",
    "    \"\"\"\n",
    "    Splits each document's text into rows based on a pattern where a row begins with a number.\n",
    "    Each row is returned as a new Document with a 'row_number' in metadata.\n",
    "    Rows are sorted in ascending order by their row number.\n",
    "    \"\"\"\n",
    "    numbered_docs = []\n",
    "    for doc in documents:\n",
    "        # Use regex to split at positions where a new line starts with one or more digits and a space.\n",
    "        # (?m) enables multiline mode and (?=^\\d+\\s) is a positive lookahead for a line beginning with digits.\n",
    "        rows = re.split(r'(?m)(?=^\\d+\\s)', doc.page_content)\n",
    "        rows = [row.strip() for row in rows if row.strip()]\n",
    "        row_tuples = []\n",
    "        for row in rows:\n",
    "            # Match the row number and the rest of the row\n",
    "            m = re.match(r'^(\\d+)\\s+(.*)', row, flags=re.DOTALL)\n",
    "            if m:\n",
    "                row_number = int(m.group(1))\n",
    "                row_text = row.strip()\n",
    "                row_tuples.append((row_number, row_text))\n",
    "        # Sort rows by the extracted row number\n",
    "        row_tuples.sort(key=lambda x: x[0])\n",
    "        for number, text in row_tuples:\n",
    "            new_doc = Document(page_content=text, metadata={\"row_number\": number})\n",
    "            numbered_docs.append(new_doc)\n",
    "    return numbered_docs\n",
    "\n",
    "# Example: assuming 'extracted_data' is a list of Document objects loaded from \"Price 2.pdf\"\n",
    "# For instance, extracted_data could be obtained via a PDF loader.\n",
    "extracted_data = load_pdf(\"/Users/shakil/Downloads/RAG-Chatbot/price/\")\n",
    "\n",
    "numbered_documents = split_into_numbered_rows(extracted_data)\n",
    "print(\"Number of numbered rows:\", len(numbered_documents))\n",
    "\n",
    "# --- Step 2: Download Hugging Face embeddings ---\n",
    "\n",
    "def download_hugging_face_embeddings():\n",
    "    embeddings = HuggingFaceEmbeddings(model_name=\"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "    return embeddings\n",
    "\n",
    "embeddings = download_hugging_face_embeddings()\n",
    "query_result = embeddings.embed_query(\"Hello world\")\n",
    "print(\"Length of Embedding Vector:\", len(query_result))\n",
    "\n",
    "# --- Step 3: Upload vector embeddings to Pinecone ---\n",
    "\n",
    "docsearch = Pinecone.from_documents(\n",
    "    documents=numbered_documents,\n",
    "    embedding=embeddings,\n",
    "    index_name=\"test\"  # Ensure this index exists in your Pinecone account\n",
    ")\n",
    "\n",
    "print(\"Price Vector embeddings uploaded to Pinecone successfully!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mchatbot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
